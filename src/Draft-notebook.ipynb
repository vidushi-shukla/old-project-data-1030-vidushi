{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)]\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 1.18.5 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.2.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 0.23.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 1.0.5 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m xgboost version 1.1.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m shap version 0.35.0 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from distutils.version import LooseVersion as Version\n",
    "import sys\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.7 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == min_ver:\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(sys.version)\n",
    "if pyversion >= \"3.7\":\n",
    "    print(OK, \"Python version is %s\" % sys.version)\n",
    "elif pyversion < \"3.7\":\n",
    "    print(FAIL, \"Python version 3.7 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % sys.version)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"1.18.5\", 'matplotlib': \"3.2.2\",'sklearn': \"0.23.1\", \n",
    "                'pandas': \"1.0.5\",'xgboost': \"1.1.1\", 'shap': \"0.35.0\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import math\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a given national park, given a species of specific nativeness, order and family, can we predict abundance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**\n",
    "\n",
    "Read data into the cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File project-data-1030-vidushi-shukla/data/species.csv does not exist: 'project-data-1030-vidushi-shukla/data/species.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-65ab9b356668>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read in the data in this cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'project-data-1030-vidushi-shukla/data/species.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'Unnamed: 13'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(df1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data1030\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data1030\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data1030\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data1030\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data1030\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File project-data-1030-vidushi-shukla/data/species.csv does not exist: 'project-data-1030-vidushi-shukla/data/species.csv'"
     ]
    }
   ],
   "source": [
    "# read in the data in this cell\n",
    "df1 = pd.read_csv('project-data-1030-vidushi-shukla/data/species.csv', low_memory=False)\n",
    "df1 = df1.loc[:, df1.columns != 'Unnamed: 13']\n",
    "# print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/parks.csv')\n",
    "# print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2,how='outer',on='Park Name')  # merging on IDs present in any dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[(df['Record Status']!='Approved')]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns seem irrelevant to the model: \n",
    "1) Species ID\n",
    "\n",
    "\n",
    "\n",
    "3) Common Names\n",
    "\n",
    "4) Park Code\n",
    "\n",
    "5) State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.columns != 'Species ID']\n",
    "df = df.loc[:, df.columns != 'Common Names']\n",
    "df = df.loc[:, df.columns != 'Park Code']\n",
    "# df = df.loc[:, df.columns != 'State']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(df['Category']!='Vascular Plant')]\n",
    "# df2 = df2[(df2['Category']!='Nonvascular Plant')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(subset=['Abundance'], inplace=True)                  Not dropping, converting to \"Missing\"\n",
    "#for x in df['Abundance']:                              # iterates through each value in each column\n",
    "#    if math.isnan(x)==True:             # if value is NaN and the column index for missing values has not been registered\n",
    "#        print(i)\n",
    "#        #col_missing = i\n",
    "# values = {'Abundance': 'Missing'}      # value = values\n",
    "df.fillna(\"Missing\", inplace = True)\n",
    "\n",
    "df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Category']!='Vascular Plant')]\n",
    "df2 = df2[(df2['Category']!='Nonvascular Plant')]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Relative abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Abundance']).plot.bar()\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('Abundance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[(df['Abundance']==\"Uncommon\")|(df['Abundance']==\"Common\")|(df['Abundance']==\"Rare\")|(df['Abundance']==\"Occasional\")|(df['Abundance']==\"Abundant\")]\n",
    "# print(df.shape)\n",
    "# print(df[(df['Category']=='Vascular Plant')].shape)\n",
    "df2 = df2[(df2['Abundance']!='Native')]\n",
    "df2 = df2[(df2['Abundance']!='Not Native')]\n",
    "df2.shape\n",
    "df = df2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Park Name: \", pd.unique(df2['Park Name']).shape[0])\n",
    "print(\"Category: \", pd.unique(df2['Category']).shape[0])\n",
    "print(\"Order: \", pd.unique(df2['Order']).shape[0])\n",
    "print(\"Family: \", pd.unique(df2['Family']).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scientific Names: \", pd.unique(df2['Scientific Name']).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Park Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Park Name: \", pd.unique(df2['Park Name']).shape[0])\n",
    "pd.value_counts(df2['Park Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Category: \", pd.unique(df2['Category']).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Category']).plot.bar(figsize = (12, 8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('count', fontsize = 14)\n",
    "plt.xlabel('Category', fontsize = 14)\n",
    "plt.savefig(\"figures\\Category Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Order: \", pd.unique(df2['Order']).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Order']).plot.bar(figsize = (24, 8))      # too many to be useful bar plot\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('Order')\n",
    "plt.savefig(\"figures\\Order Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Family: \", pd.unique(df2['Family']).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Scientific Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scientific Name: \", pd.unique(df2['Scientific Name']).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Record Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Record Status']).plot.bar(figsize = (10, 8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('count', fontsize = 14)\n",
    "plt.xlabel('Record Status', fontsize = 14)\n",
    "plt.savefig(\"figures\\Record Status Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Occurrence']).plot.bar(figsize = (10, 8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('count', fontsize = 14)\n",
    "plt.xlabel('Occurrence', fontsize = 14)\n",
    "plt.savefig(\"figures\\Occurence Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Nativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Nativeness']).plot.bar(figsize = (10, 10))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('Counts', fontsize = 14)\n",
    "plt.xlabel('Nativeness', fontsize = 14)\n",
    "plt.savefig(\"figures\\Bar Plot Nativeness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Seasonality']).plot.bar(figsize = (14, 8))\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('Seasonality')\n",
    "plt.savefig(\"figures\\Seasonality Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Conservation Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Conservation Status']).plot.bar(figsize = (12, 8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('Counts', fontsize = 14)\n",
    "plt.xlabel('Conservation Status', fontsize = 14)\n",
    "plt.savefig(\"figures\\Conservation Status Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['State']).plot.bar(figsize = (14, 8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('Counts', fontsize = 14)\n",
    "plt.xlabel('State', fontsize = 14)\n",
    "plt.savefig(\"figures\\State Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Acres (Area of Park)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.describe(df2['Acres']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Acres'].plot.hist(bins = df2['Acres'].nunique(), figsize = (14, 8))\n",
    "# plt.semilogx()\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xlabel('Area (Acres)', fontsize = 14)\n",
    "plt.ylabel('count', fontsize = 14)\n",
    "plt.savefig(\"figures\\Area Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Latitude'].plot.hist(bins = df2['Latitude'].nunique(), figsize = (14, 8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xlabel('Latitude (degrees)', fontsize = 14)\n",
    "plt.ylabel('count', fontsize = 14)\n",
    "plt.savefig(\"figures\\Latitude Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Longitude'].plot.hist(bins = df2['Longitude'].nunique(), figsize = (14, 8))\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xlabel('Longitude (degrees)', fontsize = 14)\n",
    "plt.ylabel('count', fontsize = 14)\n",
    "plt.savefig(\"figures\\Longitude Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df2['Abundance']).plot.bar(figsize = (12, 8), color = '#1E8409')\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('Counts', fontsize = 14)\n",
    "plt.xlabel('Abundance', fontsize = 14)\n",
    "plt.savefig(\"figures\\Abundance Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Scatter Matrix for the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df2, alpha = 0.2, figsize = (12, 10))\n",
    "plt.savefig(\"figures\\Scatter Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Variable EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Category vs. Park Name: Stacked bar plot: Gives a rough estimate of diversity in every park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2\n",
    "\n",
    "count_matrix = df.groupby(['Park Name', 'Category']).size().unstack()\n",
    "#print(count_matrix)\n",
    "\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1),axis=0)\n",
    "# print(count_matrix_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix_norm.plot.barh(stacked=True, figsize = (8, 24))\n",
    "\n",
    "# plt.xticks(rotation = 30, rotation_mode = \"anchor\", verticalalignment = \"top\", fontsize = 12)\n",
    "plt.xticks(fontsize = 11)\n",
    "plt.yticks(fontsize = 11)\n",
    "plt.ylabel('Park Name', fontsize = 14)\n",
    "plt.xlabel('Diversity in every park by Category', fontsize = 14)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(\"figures\\Category vs Park Name Stacked Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Category vs. area of park: Is there a relationship between the 2? Maybe bigger parks have more diversity? Or is that there are fewer big parks to begin with? Ranges of diversity discussion as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['Acres','Category']].boxplot(by='Category', figsize = (16, 10))\n",
    "plt.xticks(rotation = 30, rotation_mode = \"default\", fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.xlabel('Category', fontsize = 15)\n",
    "plt.ylabel('Area of park in acres', fontsize = 15)\n",
    "plt.suptitle(\"\")\n",
    "plt.savefig(\"figures\\Category vs Area Boxplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2\n",
    "dataset = [df[df['Category']=='Algae']['Acres'].values,\n",
    "           df[df['Category']=='Amphibian']['Acres'].values,\n",
    "           df[df['Category']=='Bird']['Acres'].values,\n",
    "           df[df['Category']=='Crab/Lobster/Shrimp']['Acres'].values,\n",
    "           df[df['Category']=='Fish']['Acres'].values,\n",
    "           df[df['Category']=='Fungi']['Acres'].values,\n",
    "           df[df['Category']=='Insect']['Acres'].values,\n",
    "           df[df['Category']=='Invertebrate']['Acres'].values,\n",
    "           df[df['Category']=='Mammal']['Acres'].values,\n",
    "           df[df['Category']=='Reptile']['Acres'].values,\n",
    "           df[df['Category']=='Slug/Snail']['Acres'].values,\n",
    "           df[df['Category']=='Spider/Scorpion']['Acres'].values]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "plt.violinplot(dataset = dataset)\n",
    "plt.xticks([1,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],['Algae', 'Amphibian', 'Bird', 'Crab/Lobster/Shrimp', 'Fish', 'Fungi', 'Insect', 'Invertebrate', 'Mammal', 'Reptile', 'Slug/Snail', 'Spider/Scorpion'], rotation = 30, rotation_mode = \"default\", fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.xlabel('Category', fontsize = 14)\n",
    "plt.ylabel('Area (Acres)', fontsize = 14)\n",
    "plt.savefig(\"figures\\Category vs Park Name Violin Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Nativeness vs. area of park: Category-specific histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['Nativeness'].unique()\n",
    "bin_range = (df['Acres'].min(),df['Acres'].max())\n",
    "\n",
    "plt.figure(figsize = (20, 8))\n",
    "for c in categories:\n",
    "    plt.hist(df[df['Nativeness']==c]['Acres'],alpha=0.5,label=c,range=bin_range,bins=100,density=True)\n",
    "# plt.semilogx()\n",
    "plt.legend()\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Acres')\n",
    "plt.savefig(\"figures\\Column Nativeness vs area of park category specific histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Nativeness vs Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['Nativeness'].unique()\n",
    "bin_range = (df['Longitude'].min(),df['Longitude'].max())\n",
    "\n",
    "plt.figure(figsize = (15, 8))\n",
    "for c in categories:\n",
    "    plt.hist(df[df['Nativeness']==c]['Longitude'],alpha=0.5,label=c,range=bin_range,bins=40,density=True)\n",
    "# plt.semilogy()\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylabel('Counts', fontsize = 14)\n",
    "plt.xlabel('Longitude (degrees)', fontsize = 14)\n",
    "plt.savefig(\"figures\\Column Nativeness vs Longitude Categorical Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Park Name vs Abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2\n",
    "\n",
    "count_matrix = df.groupby(['Park Name', 'Abundance']).size().unstack()\n",
    "#print(count_matrix)\n",
    "\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1),axis=0)\n",
    "# print(count_matrix_norm)\n",
    "\n",
    "count_matrix_norm.plot.barh(stacked=True, figsize = (15, 30))\n",
    "\n",
    "# plt.xticks(rotation = 30, rotation_mode = \"anchor\", verticalalignment = \"top\", fontsize = 12)\n",
    "plt.xticks(fontsize = 11)\n",
    "plt.yticks(fontsize = 11)\n",
    "plt.ylabel('Park Name', fontsize = 14)\n",
    "plt.xlabel('Abundance', fontsize = 14)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "plt.savefig(\"figures\\Abundance vs Park Name Stacked Bar Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Park Name vs Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['Park Name'].unique()\n",
    "bin_range = (df['Acres'].min(),df['Acres'].max())\n",
    "\n",
    "plt.figure(figsize = (20, 8))\n",
    "for c in categories:\n",
    "    plt.hist(df[df['Park Name']==c]['Acres'],alpha=0.5,label=c,range=bin_range,bins=60,density=True)\n",
    "# plt.semilogx()\n",
    "plt.legend()\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Park Name')\n",
    "plt.savefig(\"figures\\Park Name vs area of park category-specific histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) State vs Conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = df.groupby(['State', 'Conservation Status']).size().unstack()\n",
    "#print(count_matrix)\n",
    "\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1),axis=0)\n",
    "# print(count_matrix_norm)\n",
    "\n",
    "count_matrix_norm.plot.bar(stacked=True, figsize = (20, 8))\n",
    "\n",
    "# plt.xticks(rotation = 30, rotation_mode = \"anchor\", verticalalignment = \"top\", fontsize = 12)\n",
    "plt.xticks(fontsize = 11)\n",
    "plt.yticks(fontsize = 11)\n",
    "plt.ylabel('State', fontsize = 14)\n",
    "plt.xlabel('Conservation Status', fontsize = 14)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "plt.savefig(\"figures\\State vs Conservation Status Stacked Bar Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conservation = df2[(df2['Conservation Status']!='Missing')]\n",
    "count_matrix = df_conservation.groupby(['State', 'Conservation Status']).size().unstack()\n",
    "#print(count_matrix)\n",
    "\n",
    "count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1),axis=0)\n",
    "# print(count_matrix_norm)\n",
    "\n",
    "count_matrix_norm.plot.bar(stacked=True, figsize = (20, 8))\n",
    "\n",
    "# plt.xticks(rotation = 30, rotation_mode = \"anchor\", verticalalignment = \"top\", fontsize = 12)\n",
    "plt.xticks(fontsize = 11)\n",
    "plt.yticks(fontsize = 11)\n",
    "plt.ylabel('State', fontsize = 14)\n",
    "plt.xlabel('Conservation Status', fontsize = 14)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "plt.savefig(\"figures\\State vs Conservation Status without Missing Stacked Bar Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['Abundance'] \n",
    "X = df2.loc[:, df2.columns != 'Abundance'] # all other columns are features\n",
    "z = df2['Park Name']\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(X,y,train_size = 0.6,stratify=z,random_state=42)   # first split\n",
    "print('training set:',X_train.shape, y_train.shape)                           # 60% of points are in train\n",
    "# z = X_train['Park Name']\n",
    "# print(z.value_counts(normalize=True))\n",
    "\n",
    "z_other = X_other['Park Name']\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other,y_other,train_size = 0.5,stratify=z_other,random_state=42)  # second split\n",
    "print('validation set:',X_val.shape, y_val.shape)                             # 20% of points are in validation\n",
    "print('test set:',X_test.shape, y_test.shape)                                 # 20% of points are in test\n",
    "# z_other = X_other['Park Name']\n",
    "# print(z.value_counts(normalize=True))\n",
    "\n",
    "# preprocess categorical variables - used OneHotEncoder\n",
    "onehot_ftrs = ['Category', 'Order', 'Family', 'Scientific Name', 'Record Status', 'Occurrence', 'Nativeness', 'Seasonality', 'Conservation Status', 'State']                                                        # initialize the encoder\n",
    "enc = OneHotEncoder(sparse=False,handle_unknown='ignore') \n",
    "enc.fit(X_train[onehot_ftrs])                                                 # fit the training data\n",
    "print('   feature names:',enc.get_feature_names(onehot_ftrs).shape)\n",
    "onehot_train = enc.transform(X_train[onehot_ftrs])                            # transform X_train\n",
    "onehot_val = enc.transform(X_val[onehot_ftrs])                                # transform X_val\n",
    "onehot_test = enc.transform(X_test[onehot_ftrs])                              # transform X_test\n",
    "                       \n",
    "# preprocess continuous variables - used StandardScaler\n",
    "std_ftrs = ['Acres', 'Latitude', 'Longitude']\n",
    "scaler = StandardScaler()\n",
    "scaler_train = scaler.fit_transform(X_train[std_ftrs])                        # fit the training data, transform X_train\n",
    "scaler_val = scaler.transform(X_val[std_ftrs])                                # transform X_val\n",
    "scaler_test = scaler.transform(X_test[std_ftrs])                              # transform X_test\n",
    "print('   ', scaler_test[100])\n",
    "        \n",
    "# preprocess Y - used LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_val_le = le.transform(y_val)\n",
    "y_test_le = le.transform(y_test)\n",
    "print(y_test_le)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['Abundance'] \n",
    "X = df2.loc[:, df2.columns != 'Abundance'] # all other columns are features\n",
    "groups = df2['Park Name']\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=3, train_size=.6, random_state=42)                  # split into training and other sets\n",
    "for train_index, other_index in gss.split(X, y, groups):\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_other = X.iloc[other_index]\n",
    "    y_other = y.iloc[other_index]\n",
    "    print('   training set:',X_train.shape, y_train.shape) \n",
    "    # print(X_train[['Park Name']].head())\n",
    "\n",
    "    gss2 = GroupShuffleSplit(n_splits=1, train_size=.5, random_state=42)    \n",
    "    groups_other = X_other[['Park Name']]\n",
    "    for val_index, test_index in gss2.split(X_other,y_other, groups_other):           # split into validation and test sets\n",
    "        X_val = X_other.iloc[val_index]\n",
    "        y_val = y_other.iloc[val_index]\n",
    "        X_test = X_other.iloc[test_index]\n",
    "        y_test = y_other.iloc[test_index]\n",
    "        \n",
    "        print('   validation set:',X_val.shape, y_val.shape) \n",
    "        print('   test set:',X_test.shape, y_test.shape) \n",
    "        # print(X_val[['Park Name']].head())\n",
    "        # print(X_test[['Park Name']].head())\n",
    "        \n",
    "        # preprocess categorical variables - used OneHotEncoder\n",
    "        onehot_ftrs = ['Category', 'Order', 'Family', 'Scientific Name', 'Record Status', 'Occurrence', 'Nativeness', 'Seasonality', 'Conservation Status', 'State']                                                        # initialize the encoder\n",
    "        enc = OneHotEncoder(sparse=False,handle_unknown='ignore') \n",
    "        enc.fit(X_train[onehot_ftrs])                                                 # fit the training data\n",
    "        print('   feature names:',enc.get_feature_names(onehot_ftrs).shape)\n",
    "        onehot_train = enc.transform(X_train[onehot_ftrs])                            # transform X_train\n",
    "        onehot_val = enc.transform(X_val[onehot_ftrs])                                # transform X_val\n",
    "        onehot_test = enc.transform(X_test[onehot_ftrs])                              # transform X_test\n",
    "                       \n",
    "        # preprocess continuous variables - used StandardScaler\n",
    "        std_ftrs = ['Acres', 'Latitude', 'Longitude']\n",
    "        scaler = StandardScaler()\n",
    "        scaler_train = scaler.fit_transform(X_train[std_ftrs])                        # fit the training data, transform X_train\n",
    "        scaler_val = scaler.transform(X_val[std_ftrs])                                # transform X_val\n",
    "        scaler_test = scaler.transform(X_test[std_ftrs])                              # transform X_test\n",
    "        print('   ', scaler_test[100])\n",
    "        \n",
    "        # preprocess Y - used LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        y_train_le = le.fit_transform(y_train)\n",
    "        y_val_le = le.transform(y_val)\n",
    "        y_test_le = le.transform(y_test)\n",
    "        print(y_test_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
